{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73c4fb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON TO CSV\n",
    "import json\n",
    "import csv\n",
    "\n",
    "# open the json file in read mode\n",
    "with open(r'D:\\modules\\Msc_Data_Science\\Data_Science_Fundamentals\\CETM50\\assignment\\user_data.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "    # create a csv file\n",
    "    json_file_write = open(r'D:\\modules\\Msc_Data_Science\\Data_Science_Fundamentals\\CETM50\\assignment\\json_to_csv.csv', 'w', newline='')\n",
    "    csv_writer = csv.writer(json_file_write)\n",
    "    \n",
    "    # counter to iterate over the csv file and write the first line (header)\n",
    "    counter = 0\n",
    "    for idx in data:\n",
    "        if counter == 0:\n",
    "            header = idx.keys()\n",
    "            csv_writer.writerow(header)\n",
    "            break\n",
    "    \n",
    "    # for loop to fill the csv file with values from the json file\n",
    "    for idx in data:\n",
    "        if counter == 0:\n",
    "            counter += 1\n",
    "        csv_writer.writerow(idx.values())\n",
    "    \n",
    "    # close the csv file\n",
    "    json_file_write.close()\n",
    "    \n",
    "# open the CSV file in read mode\n",
    "with open(r'D:\\modules\\Msc_Data_Science\\Data_Science_Fundamentals\\CETM50\\assignment\\json_to_csv.csv', 'r') as json_file_read:\n",
    "    # create a CSV reader object\n",
    "    reader = csv.reader(json_file_read)\n",
    "\n",
    "    # read the contents of the file into memory\n",
    "    labels = list(reader)\n",
    "    \n",
    "    \n",
    "    # loop to iterate over the json file to check for values that are = \"amount\"\n",
    "    for line_no , line in enumerate(json_file_read):\n",
    "        # line hwwa lcontenu\n",
    "        # w line_no hwwa indice dyal ligne\n",
    "        if \"amount\" in line.lower():\n",
    "            line_num.append(line_no)\n",
    "                \n",
    "    # create two lists to store their values\n",
    "    value_amount = []\n",
    "    value_time_period_years = []\n",
    "    line_num = []\n",
    "    # for loop to store values that are \"values\" in the first list and those that are \"time_period..\" in the the second list\n",
    "    for idx in line_num:\n",
    "        dictt = data[idx-1]\n",
    "        \n",
    "        value_amount.append(dictt[\"debt\"][\"amount\"])\n",
    "        value_time_period_years.append(dictt[\"debt\"][\"time_period_years\"])\n",
    "        \n",
    "    # delete the old values (first version of jsontocsv file)\n",
    "    for i, row in enumerate(labels):\n",
    "        for j, cell in enumerate(row):\n",
    "            if 'amount' in cell:\n",
    "                # Delete the value from the cell\n",
    "                labels[i][j] = ''\n",
    "    \n",
    "    \n",
    "# Add the new column name to the header row\n",
    "    labels[0].append('debt')\n",
    "    labels[0].append('debt_amount')\n",
    "    labels[0].append('debt_time_period_years')\n",
    "\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "with open(r'D:\\modules\\Msc_Data_Science\\Data_Science_Fundamentals\\CETM50\\assignment\\json_to_csv.csv', 'w', newline='') as data_file_write:\n",
    "    # Create a CSV writer object\n",
    "    writer = csv.writer(data_file_write)\n",
    "    # Write the rows back to the file\n",
    "    for row in labels:\n",
    "        writer.writerow(row)\n",
    "    \n",
    "    \n",
    "    for line_no , line in enumerate(data[line_no][12]):\n",
    "        if line_no == line_num:\n",
    "            writer.writerow(value_amount[line_no])\n",
    "            writer.writerow(value_time_period_years[line_no])\n",
    "           \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418b1d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "6dc181f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SORT JSON_TO_CSV FILES TO MERGE THEM\n",
    "\n",
    "import csv\n",
    "\n",
    "# Open the CSV file in read mode\n",
    "with open(r'D:\\modules\\Msc_Data_Science\\Data_Science_Fundamentals\\CETM50\\assignment\\json_to_csv.csv', 'r') as csv_file_read:\n",
    "    \n",
    "    # create a CSV reader object\n",
    "    reader = csv.reader(csv_file_read)\n",
    "    \n",
    "    # read the rows of the CSV file into a list, excluding the first row\n",
    "    rows = list(reader)[1:]\n",
    "    \n",
    "    # Get the index of the column that i want to sort by\n",
    "    with open(r'D:\\modules\\Msc_Data_Science\\Data_Science_Fundamentals\\CETM50\\assignment\\json_to_csv.csv', 'r') as csv_file_read:\n",
    "        col_names = next(csv.reader(csv_file_read))\n",
    "    \n",
    "    # to choose which column name i want to sort my file in alphabetical order\n",
    "    sort_by_last_name = col_names.index('lastName')\n",
    "    \n",
    "    # take an argument row, and return the value at a specific index of that row, specified by the sort_by_last_name variable.\n",
    "    rows.sort(key=lambda row: row[sort_by_last_name])\n",
    "    \n",
    "    # insert the first row back into the list at the beginning\n",
    "    with open(r'D:\\modules\\Msc_Data_Science\\Data_Science_Fundamentals\\CETM50\\assignment\\json_to_csv.csv', 'r') as csv_file_read:\n",
    "        line = next(csv.reader(csv_file_read))\n",
    "    rows.insert(0, line)\n",
    "    \n",
    "# create a new csv file where we will have the sorted values\n",
    "with open(r'D:\\modules\\Msc_Data_Science\\Data_Science_Fundamentals\\CETM50\\assignment\\sorted_json_to_csv.csv', 'w', newline='') as csv_file_write:\n",
    "    \n",
    "    writer = csv.writer(csv_file_write)\n",
    "    \n",
    "    # Write the sorted rows back to the CSV file\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa842cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "2f01781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XML TO CSV\n",
    "from xml.etree import ElementTree\n",
    "import csv\n",
    "\n",
    "# to navigate the content of the XML file.\n",
    "xml = ElementTree.parse(r\"D:\\modules\\Msc_Data_Science\\Data_Science_Fundamentals\\CETM50\\assignment\\user_data.xml\")\n",
    "\n",
    "# create the csv file where we will put the conversion of the xml file\n",
    "with open(r\"D:\\modules\\Msc_Data_Science\\Data_Science_Fundamentals\\CETM50\\assignment\\xml_to_csv.csv\",'w',newline='') as csv_file_write:\n",
    "    csv_file_write_writer = csv.writer(csv_file_write)\n",
    "\n",
    "    # ADD THE HEADER TO CSV FILE\n",
    "    csv_file_write_writer.writerow([\"address_postcode\",\"commute_distance\",\"company\",\"pension\",\"salary\",\"marital_status\",\"dependants\",\"retired\",\"sex\",\"age\",\"lastName\",\"firstName\"])\n",
    "    \n",
    "    # search all elements with \"user\"\n",
    "    for user in root.findall('user'):\n",
    "        address_postcode = user.get('address_postcode')\n",
    "        commute_distance = user.get('commute_distance')\n",
    "        company = user.get('company')\n",
    "        pension = user.get('pension')\n",
    "        salary = user.get('salary')\n",
    "        marital_status = user.get('marital_status')\n",
    "        dependants = user.get('dependants')\n",
    "        retired = user.get('retired')\n",
    "        sex = user.get('sex')\n",
    "        age = user.get('age')\n",
    "        lastName = user.get('lastName')\n",
    "        firstName  = user.get('firstName')\n",
    "\n",
    "        csv_line = [address_postcode, commute_distance, company, pension, salary, marital_status, dependants, retired, sex, age, lastName, firstName]\n",
    "        # print(csv_line)\n",
    "        csv_file_write_writer.writerow(csv_line)\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1fa021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "df6721f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SORT XML_TO_CSV FILES TO MERGE THEM\n",
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "with open(r'D:\\modules\\Msc_Data_Science\\Data_Science_Fundamentals\\CETM50\\assignment\\xml_to_csv.csv', 'r') as csv_file:\n",
    "\n",
    "    reader = csv.reader(csv_file)\n",
    "\n",
    "    rows = list(reader)[1:]\n",
    "\n",
    "    with open(r'D:\\modules\\Msc_Data_Science\\Data_Science_Fundamentals\\CETM50\\assignment\\xml_to_csv.csv', 'r') as csv_file:\n",
    "        col_names = next(csv.reader(csv_file))\n",
    "    sort_by_last_name = col_names.index('lastName')\n",
    "\n",
    "    rows.sort(key=lambda row: row[sort_by_last_name])\n",
    "\n",
    "    with open(r'D:\\modules\\Msc_Data_Science\\Data_Science_Fundamentals\\CETM50\\assignment\\xml_to_csv.csv', 'r') as csv_file:\n",
    "        line = next(csv.reader(csv_file))\n",
    "    rows.insert(0, line)\n",
    "\n",
    "with open(r'D:\\modules\\Msc_Data_Science\\Data_Science_Fundamentals\\CETM50\\assignment\\sorted_xml_to_csv.csv', 'w', newline='') as csv_file:\n",
    "\n",
    "    writer = csv.writer(csv_file)\n",
    "\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8295cef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "88690ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SORT CSV FILE TO COMBINE \n",
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "with open(r'D:\\modules\\Msc_Data_Science\\Data_Science_Fundamentals\\CETM50\\assignment\\user_data.csv', 'r') as csv_file:\n",
    "    \n",
    "    reader = csv.reader(csv_file)\n",
    "    \n",
    "    rows = list(reader)[1:]\n",
    "    \n",
    "    with open(r'D:\\modules\\Msc_Data_Science\\Data_Science_Fundamentals\\CETM50\\assignment\\user_data.csv', 'r') as csv_file:\n",
    "        col_names = next(csv.reader(csv_file))\n",
    "    sort_by_last_name = col_names.index('Second Name')\n",
    "    \n",
    "    rows.sort(key=lambda row: row[sort_by_last_name])\n",
    "    \n",
    "    with open(r'D:\\modules\\Msc_Data_Science\\Data_Science_Fundamentals\\CETM50\\assignment\\user_data.csv', 'r') as csv_file:\n",
    "        line = next(csv.reader(csv_file))\n",
    "    rows.insert(0, line)\n",
    "\n",
    "with open(r'D:\\modules\\Msc_Data_Science\\Data_Science_Fundamentals\\CETM50\\assignment\\sorted_csv_to_csv.csv', 'w', newline='') as csv_file:\n",
    "    \n",
    "    writer = csv.writer(csv_file)\n",
    "    \n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29289416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85d76d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE THE 3 CSV FILES (CSV XML W JSON) IN ONE CSV FILE\n",
    "\n",
    "import csv\n",
    "\n",
    "# the first CSV file in read mode\n",
    "with open(r'D:\\modules\\Msc_Data_Science\\Data_Science_Fundamentals\\CETM50\\assignment\\sorted_csv_to_csv.csv', 'r') as csv_file1:\n",
    "    # Create a CSV reader object\n",
    "    reader1 = csv.reader(csv_file1)\n",
    "\n",
    "    # Read the contents of the file into memory\n",
    "    lines1 = list(reader1)\n",
    "\n",
    "# the second CSV file in read mode\n",
    "with open(r'D:\\modules\\Msc_Data_Science\\Data_Science_Fundamentals\\CETM50\\assignment\\sorted_xml_to_csv.csv', 'r') as csv_file2:\n",
    "    # Create a CSV reader object\n",
    "    reader2 = csv.reader(csv_file2)\n",
    "\n",
    "    # Read the contents of the file into memory\n",
    "    lines2 = list(reader2)\n",
    "\n",
    "# the third CSV file in read mode\n",
    "with open(r'D:\\modules\\Msc_Data_Science\\Data_Science_Fundamentals\\CETM50\\assignment\\sorted_json_to_csv.csv', 'r') as csv_file3:\n",
    "    # Create a CSV reader object\n",
    "    reader3 = csv.reader(csv_file3)\n",
    "\n",
    "    # Read the contents of the file into memory\n",
    "    lines3 = list(reader3)\n",
    "\n",
    "# concatenate the columns from the three files\n",
    "rows = []\n",
    "for i in range(len(lines1)):\n",
    "    rows.append(lines1[i] + lines2[i] + lines3[i])\n",
    "\n",
    "# open the new CSV file in write mode\n",
    "with open(r'D:\\modules\\Msc_Data_Science\\Data_Science_Fundamentals\\CETM50\\assignment\\concat_data_csv.csv', 'w', newline='') as csv_file_write:\n",
    "    # Create a CSV writer object\n",
    "    writer = csv.writer(csv_file_write)\n",
    "\n",
    "    # write the rows to the new file\n",
    "    for row in rows:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb6a248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0aa627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DELETE THE DUPLICATED COLUMNS FROM THE COMBINED CSV FILE\n",
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "with open(r'D:\\modules\\Msc_Data_Science\\Data_Science_Fundamentals\\CETM50\\assignment\\concat_data_csv.csv', 'r') as csv_file_read:\n",
    "\n",
    "    reader = csv.DictReader(csv_file_read)\n",
    "\n",
    "    rows = list(reader)\n",
    "   \n",
    "\n",
    "\n",
    "# one to delete manually\n",
    "column_name = ['firstName','age','lastName','sex']\n",
    "for row in rows:\n",
    "    for elt in column_name:\n",
    "        del row[elt]\n",
    "\n",
    "with open(r'D:\\modules\\Msc_Data_Science\\Data_Science_Fundamentals\\CETM50\\assignment\\concat_data_csv.csv', 'w', newline='') as csv_file_write:\n",
    "    # get the key (column name) of the first row\n",
    "    # to delete automatically\n",
    "    fieldnames = list(rows[0].keys())\n",
    "    # check if any fieldname is repeated\n",
    "    for fieldname in fieldnames:\n",
    "        if fieldnames.count(fieldname) > 1:\n",
    "            # delete the repeated one\n",
    "            fieldnames.remove(fieldname)\n",
    "            \n",
    "    \n",
    "    writer = csv.DictWriter(csv_file_write, fieldnames=fieldnames)\n",
    "    \n",
    "    \n",
    "    # Write the header row\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write the rows back to the file\n",
    "    for row in rows:\n",
    "        writer.writerow({field: row[field] for field in fieldnames})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba9bc79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "id": "a3ee2675",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [769]\u001b[0m, in \u001b[0;36m<cell line: 74>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmodules\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMsc_Data_Science\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mData_Science_Fundamentals\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCETM50\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124massignment\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mconcat_data_csv.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m csv_file:\n\u001b[0;32m     75\u001b[0m     csv_reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(csv_file)\n\u001b[1;32m---> 76\u001b[0m     col_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m db_session:\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;66;03m# looping over each row in the csv_reader object\u001b[39;00m\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m csv_reader:\n\u001b[0;32m     80\u001b[0m             \u001b[38;5;66;03m# mapping the column names\u001b[39;00m\n",
      "File \u001b[1;32mD:\\systemAlienWare\\Anaconda3\\lib\\csv.py:111\u001b[0m, in \u001b[0;36mDictReader.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_num \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m# Used only for its side effect.\u001b[39;00m\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfieldnames\n\u001b[1;32m--> 111\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreader\u001b[38;5;241m.\u001b[39mline_num\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# unlike the basic reader, we prefer not to return blanks,\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# because we will typically wind up with a dict full of None\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# values\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "# TO UPLOAD THE DATA TO THE DATABASE\n",
    "\n",
    "from pony.orm import *\n",
    "import csv\n",
    "\n",
    "\n",
    "# Connect to the database\n",
    "db = Database()\n",
    "db.bind(provider='mysql', host='europa.ashley.work', user='student_bi27ty', passwd='iE93F2@8EhM@1zhD&u9M@K', db='student_bi27ty')\n",
    "\n",
    "\n",
    "\n",
    "# make the mapping\n",
    "column_name_mapping = {\n",
    "    \"First Name\": \"First_Name\",\n",
    "    \"Second Name\": \"Second_Name\",\n",
    "    \"Age (Years)\": \"Age\",\n",
    "    \"sex\": \"Sex\",\n",
    "    \"Vehicle Make\": \"Vehicle_Make\",\n",
    "    \"Vehicle Model\": \"Vehicle_Model\",\n",
    "    \"Vehicle Year\": \"Vehicle_Year\",\n",
    "    \"Vehicle Type\": \"Vehicle_Type\",\n",
    "    \"address_postcode\": \"address_postcode\",\n",
    "    \"commute_distance\": \"commute_distance\",\n",
    "    \"company\": \"company\",\n",
    "    \"pension\": \"pension\",\n",
    "    \"salary\": \"salary\",\n",
    "    \"marital_status\": \"marital_status\",\n",
    "    \"dependants\": \"dependants\",\n",
    "    \"retired\": \"retired\",\n",
    "    \"iban\": \"iban\",\n",
    "    \"credit_card_number\": \"credit_card_number\",\n",
    "    \"credit_card_security_code\": \"credit_card_security_code\",\n",
    "    \"credit_card_start_date\": \"credit_card_start_date\",\n",
    "    \"credit_card_end_date\": \"credit_card_end_date\",\n",
    "    \"address_main\": \"address_main\",\n",
    "    \"address_city\": \"address_city\",\n",
    "    \"debt\": \"debt\",\n",
    "    \"debt_amount\": \"debt_amount\",\n",
    "    \"debt_time_period_years\": \"debt_time_period_years\",\n",
    "}\n",
    "\n",
    "class Data_Frame(db.Entity):\n",
    "    First_Name = Required(str)\n",
    "    Second_Name = Required(str)\n",
    "    Age = Required(int)\n",
    "    Sex = Required(str)\n",
    "    Vehicle_Make = Required(str)\n",
    "    Vehicle_Model = Required(str)\n",
    "    Vehicle_Year = Required(str)\n",
    "    Vehicle_Type = Required(str)\n",
    "    address_postcode = Required(str)\n",
    "    commute_distance = Required(str)\n",
    "    company = Required(str)\n",
    "    pension = Required(str)\n",
    "    salary = Required(str)\n",
    "    marital_status = Required(str)\n",
    "    dependants = Required(str)\n",
    "    retired = Required(str)\n",
    "    iban = Required(str)\n",
    "    credit_card_number = Required(str)\n",
    "    credit_card_security_code = Required(str)\n",
    "    credit_card_start_date = Required(str)\n",
    "    credit_card_end_date = Required(str)\n",
    "    address_main = Required(str)\n",
    "    address_city = Required(str)\n",
    "    debt = Optional(str)\n",
    "    debt_amount = Optional(str)\n",
    "    debt_time_period_years = Optional(str)\n",
    "    \n",
    "    \n",
    "# create the table in the database\n",
    "db.generate_mapping(create_tables=True)\n",
    "with open(r'D:\\modules\\Msc_Data_Science\\Data_Science_Fundamentals\\CETM50\\assignment\\concat_data_csv.csv', 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    col_names = next(reader)\n",
    "    with db_session:\n",
    "        # looping over each row in the csv_reader object\n",
    "        for row in csv_reader:\n",
    "            # mapping the column names\n",
    "            data = Data_Frame(**{column_name_mapping.get(col_names[i], col_names[i]): row[i] if row[i] != \"\" else \"N/A\" for i in range(len(col_names))})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7577e848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "id": "43755ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1 : Name Shane found.\n",
      "Line 1 : Name Chambers found.\n",
      "Line 1 : Security code: 935\n",
      "Line 2 : Name Lane found.\n",
      "Line 2 : Name Joshua found.\n",
      "Line 2 : Salary £2100 found.\n",
      "Line 3 : Name Suzanne found.\n",
      "Line 3 : Name Wright found.\n",
      "Line 4 : Name Hannah found.\n",
      "Line 4 : Name Dunn found.\n",
      "Line 4 : Salary £22358 found.\n",
      "Line 4 : Percentage of [0.15] % found.\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTION OF useful informations from txt file\n",
    "\n",
    "import csv\n",
    "import re\n",
    "\n",
    "# Read CSV file\n",
    "with open(r'D:\\modules\\Msc_Data_Science\\Data_Science_Fundamentals\\CETM50\\assignment\\concat_data_csv.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    first_names = []\n",
    "    second_names = []\n",
    "    names = []\n",
    "    for row in reader:\n",
    "        first_names.append(row[\"First Name\"])\n",
    "        second_names.append(row[\"Second Name\"])\n",
    "\n",
    "\n",
    "with open(r'D:\\modules\\Msc_Data_Science\\Data_Science_Fundamentals\\CETM50\\assignment\\user_data.txt', 'r') as file:\n",
    "    text_lines = file.readlines()\n",
    "\n",
    "# extraction of names and salaries from text file\n",
    "for i, line in enumerate(text_lines):\n",
    "    text_names = line.split()\n",
    "    text_names = [x for x in text_names if x[0].isupper()]\n",
    "    text_names = [name.replace('\"',' ').replace('!',' ').replace(',',' ').replace('\\\\',' ').replace('%',' ').replace('#',' ') for name in text_names]\n",
    "\n",
    "    # Check if names from text file match any names in CSV file\n",
    "    for name in text_names:\n",
    "        if (name in first_names) or (name in second_names):\n",
    "            print(\"Line\", i+1, \": Name\",name,\"found.\")\n",
    "\n",
    "    # Check if salary is in the line\n",
    "    salary = re.search(r'£\\d+', line)\n",
    "    if salary:\n",
    "        print(\"Line\", i+1, \": Salary\",salary.group(0),\"found.\")\n",
    "        \n",
    "    percentage = re.findall(r'\\d+\\.\\d+%', line)\n",
    "    if percentage:\n",
    "        percentage = [float(val.replace(\"%\", \"\")) for val in percentage]\n",
    "        print(\"Line\", i+1, \": Percentage of\",percentage,\"% found.\")\n",
    "        \n",
    "    # security code\n",
    "    sec_code = re.search(r'\\\"(\\d{3})\\\"', line)\n",
    "    if sec_code:\n",
    "        print(\"Line\", i+1, \": Security code:\", sec_code.group(1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16e2bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6058323e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db03e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469f0302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05c4a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0123ffd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bad57a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae758882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb84440b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe9e9be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d69044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6350e0df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc5645e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3b8aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2ebf1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "946272e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1d4f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e98c627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9331da15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e429598f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08bd60b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c1eb93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37956e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af439c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7523f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195bf676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9fff8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db051c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d8d020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ce6990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c532e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9754e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "e2c44c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b770303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1c132e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559063c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac1ebb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8773537d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275b8b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0cf070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc257d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b995abf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bf4c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbd8836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a0e18b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4813fedc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8a2fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad8201e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5a55fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079197e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
